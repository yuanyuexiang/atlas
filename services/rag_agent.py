"""
RAG Agent - åŸºäº Milvus çš„æ™ºèƒ½é—®ç­”ä»£ç†
ä½¿ç”¨ LangChain v1.0+ Agent æ¡†æ¶å®ç°
"""
import os
import json
import uuid
from datetime import datetime
from typing import Optional, List
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain.agents import create_agent
from langchain_core.tools import tool
from services.milvus_service import get_milvus_store

load_dotenv()


class RAGAgent:
    """åŸºäº Milvus çš„ RAG Agent"""
    
    def __init__(self, agent_name: str, system_prompt: str = None):
        """
        åˆå§‹åŒ– RAG Agent
        
        Args:
            agent_name: æ™ºèƒ½ä½“åç§°
            system_prompt: ç³»ç»Ÿæç¤ºè¯
        """
        self.agent_name = agent_name
        self.system_prompt = system_prompt or self._get_default_prompt()
        self.milvus_store = get_milvus_store()
        self.vector_store = None
        self.agent = None
        self.chat_history = []
        
        # å…ƒæ•°æ®è·¯å¾„
        self.metadata_dir = os.getenv("METADATA_DIR", "metadata_store")
        os.makedirs(self.metadata_dir, exist_ok=True)
        self.files_meta_path = os.path.join(self.metadata_dir, f"{agent_name}.json")
        
        # åˆå§‹åŒ–
        self._init_vector_store()
        self._create_agent()
    
    def _get_default_prompt(self) -> str:
        """è·å–é»˜è®¤ç³»ç»Ÿæç¤ºè¯"""
        return (
            "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥åŸºäºçŸ¥è¯†åº“å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n"
            "é‡è¦è§„åˆ™:\n"
            "1. ä½¿ç”¨æ£€ç´¢åˆ°çš„çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ï¼Œå‡†ç¡®å¼•ç”¨ç›¸å…³ä¿¡æ¯\n"
            "2. å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œè¯šå®å‘ŠçŸ¥ç”¨æˆ·\n"
            "3. ä½¿ç”¨æ¸…æ™°æ˜“æ‡‚çš„è¯­è¨€ç»„ç»‡ç­”æ¡ˆ\n"
            "4. å¯¹äºç›¸åŒçš„é—®é¢˜ï¼Œå§‹ç»ˆç»™å‡ºä¸€è‡´çš„ç­”æ¡ˆ"
        )
    
    def _init_vector_store(self):
        """åˆå§‹åŒ–å‘é‡å­˜å‚¨"""
        self.vector_store = self.milvus_store.get_vector_store(self.agent_name)
        print(f"âœ… å‘é‡å­˜å‚¨å·²å°±ç»ª: {self.agent_name}")
    
    def _create_agent(self):
        """ä½¿ç”¨ LangChain v1.0+ Agent æ¡†æ¶åˆ›å»º Agent"""
        # 1. åˆ›å»º LLM
        model = ChatOpenAI(
            temperature=0,
            max_tokens=1000,
            model=os.getenv("CHAT_MODEL", "gpt-3.5-turbo"),
            base_url=os.getenv("OPENAI_BASE_URL"),
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # 2. ä½¿ç”¨ @tool è£…é¥°å™¨å®šä¹‰å·¥å…·ï¼ˆLangChain v1.0+ æ ‡å‡†æ–¹å¼ï¼‰
        agent_name = self.agent_name  # é—­åŒ…æ•è·
        milvus_store = self.milvus_store
        
        @tool
        def knowledge_base_search(query: str) -> str:
            """æœç´¢æ™ºèƒ½ä½“çš„çŸ¥è¯†åº“è·å–ç›¸å…³æ–‡æ¡£å†…å®¹ã€‚
            
            å½“ç”¨æˆ·è¯¢é—®äº§å“ã€æœåŠ¡ã€æ”¿ç­–ç­‰éœ€è¦å‚è€ƒæ–‡æ¡£çš„é—®é¢˜æ—¶ï¼Œåº”è¯¥ä½¿ç”¨æ­¤å·¥å…·ã€‚
            
            Args:
                query: æœç´¢æŸ¥è¯¢ï¼ˆç”¨æˆ·é—®é¢˜æˆ–å…³é”®è¯ï¼‰
                
            Returns:
                çŸ¥è¯†åº“ä¸­ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
            """
            results = milvus_store.search_similar(agent_name, query, top_k=3)
            if not results:
                return "æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"
            return "\n\n---\n\n".join(
                f"æ–‡æ¡£ç‰‡æ®µ {i+1}:\n{r['content']}" 
                for i, r in enumerate(results[:3])
            )
        
        tools = [knowledge_base_search]
        
        # 3. ä½¿ç”¨ create_agentï¼ˆLangChain v1.0+ å®˜æ–¹æ¨è APIï¼‰
        self.agent = create_agent(
            model=model,
            tools=tools,
            system_prompt=f"""{self.system_prompt}

            ä½ å¯ä»¥ä½¿ç”¨ knowledge_base_search å·¥å…·æ¥æŸ¥è¯¢çŸ¥è¯†åº“ï¼Œè·å–å‡†ç¡®çš„ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

            é‡è¦è§„åˆ™ï¼š
            1. å¯¹äºéœ€è¦å‚è€ƒæ–‡æ¡£çš„é—®é¢˜ï¼Œå¿…é¡»å…ˆä½¿ç”¨ knowledge_base_search å·¥å…·æŸ¥è¯¢çŸ¥è¯†åº“
            2. åŸºäºæ£€ç´¢åˆ°çš„çŸ¥è¯†åº“å†…å®¹å‡†ç¡®å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
            3. å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œè¯šå®å‘ŠçŸ¥ç”¨æˆ·
            4. å›ç­”è¦æ¸…æ™°ã€å‡†ç¡®ã€å‹å¥½ã€ä¸“ä¸š
            5. å¼•ç”¨çŸ¥è¯†åº“å†…å®¹æ—¶è¦è‡ªç„¶æµç•…ï¼Œä¸è¦ç”Ÿç¡¬å¤åˆ¶ç²˜è´´"""
        )
        
        print(f"âœ… LangChain v1.0+ Agent åˆ›å»ºæˆåŠŸ (create_agent): {self.agent_name}")
    
    def ask(self, question: str) -> str:
        """
        å‘ Agent æé—®ï¼ˆä½¿ç”¨ LangChain v1.0+ create_agentï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            str: Agent å›ç­”
        """
        try:
            # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦ä¸ºç©º
            stats = self.milvus_store.get_collection_stats(self.agent_name)
            if stats and stats.get("total_vectors", 0) == 0:
                empty_kb_msg = "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚ç›®å‰æˆ‘çš„çŸ¥è¯†åº“è¿˜æ˜¯ç©ºçš„ï¼Œè¯·ç®¡ç†å‘˜å…ˆä¸Šä¼ ç›¸å…³æ–‡æ¡£ï¼Œæˆ‘æ‰èƒ½æ›´å¥½åœ°ä¸ºæ‚¨æœåŠ¡ã€‚"
                return empty_kb_msg
            
            # æ„å»ºæ¶ˆæ¯å†å²ï¼ˆLangGraph State æ ¼å¼ï¼‰
            messages = []
            # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆä¿ç•™æœ€è¿‘10è½®ï¼‰
            messages.extend(self.chat_history[-10:])
            # æ·»åŠ å½“å‰ç”¨æˆ·é—®é¢˜
            messages.append({"role": "user", "content": question})
            
            # ä½¿ç”¨ Agent æ‰§è¡Œï¼ˆLangGraph APIï¼‰
            result = self.agent.invoke({"messages": messages})
            
            # æå–æœ€åä¸€æ¡ AI æ¶ˆæ¯
            final_messages = result.get("messages", [])
            if final_messages:
                answer = final_messages[-1].content
            else:
                answer = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
            
            # æ›´æ–°å¯¹è¯å†å²ï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼‰
            from datetime import datetime, UTC
            timestamp = datetime.now(UTC).isoformat()
            
            self.chat_history.append(HumanMessage(
                content=question,
                additional_kwargs={"timestamp": timestamp}
            ))
            self.chat_history.append(AIMessage(
                content=answer,
                additional_kwargs={"timestamp": timestamp}
            ))
            
            return answer
            
        except Exception as e:
            print(f"âŒ Agent å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
    
    async def ask_stream(self, question: str):
        """
        å‘ Agent æé—®ï¼ˆæµå¼å“åº”ï¼ŒLangChain v1.0+ create_agentï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Yields:
            str: é€å—è¿”å›çš„å›ç­”å†…å®¹
        """
        try:
            # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦ä¸ºç©º
            stats = self.milvus_store.get_collection_stats(self.agent_name)
            if stats and stats.get("total_vectors", 0) == 0:
                empty_kb_msg = "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚ç›®å‰æˆ‘çš„çŸ¥è¯†åº“è¿˜æ˜¯ç©ºçš„ï¼Œè¯·ç®¡ç†å‘˜å…ˆä¸Šä¼ ç›¸å…³æ–‡æ¡£ï¼Œæˆ‘æ‰èƒ½æ›´å¥½åœ°ä¸ºæ‚¨æœåŠ¡ã€‚"
                yield empty_kb_msg
                return
            
            # æ„å»ºæ¶ˆæ¯å†å²
            messages = []
            messages.extend(self.chat_history[-10:])
            messages.append({"role": "user", "content": question})
            
            # Agent æµå¼å“åº”ï¼ˆLangGraph stream APIï¼‰
            full_response = ""
            last_content_length = 0
            
            async for chunk in self.agent.astream(
                {"messages": messages},
                stream_mode="values"  # æµå¼è¾“å‡ºçŠ¶æ€å€¼
            ):
                # è·å–æœ€æ–°æ¶ˆæ¯
                latest_messages = chunk.get("messages", [])
                if latest_messages:
                    latest_message = latest_messages[-1]
                    
                    # å¦‚æœæ˜¯ AI æ¶ˆæ¯ï¼Œæµå¼è¾“å‡ºå†…å®¹
                    if hasattr(latest_message, "content") and latest_message.content:
                        content = latest_message.content
                        # åªè¾“å‡ºæ–°å¢çš„å†…å®¹ï¼ˆå¢é‡è¾“å‡ºï¼‰
                        if len(content) > last_content_length:
                            new_content = content[last_content_length:]
                            last_content_length = len(content)
                            full_response = content
                            yield new_content
                    
                    # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼Œæ‰“å°æ—¥å¿—
                    elif hasattr(latest_message, "tool_calls") and latest_message.tool_calls:
                        for tc in latest_message.tool_calls:
                            print(f"ğŸ”§ Agent æ­£åœ¨ä½¿ç”¨å·¥å…·: {tc.get('name', 'unknown')}")
            
            # æ›´æ–°å¯¹è¯å†å²ï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼‰
            if full_response:
                from datetime import datetime, UTC
                timestamp = datetime.now(UTC).isoformat()
                
                self.chat_history.append(HumanMessage(
                    content=question,
                    additional_kwargs={"timestamp": timestamp}
                ))
                self.chat_history.append(AIMessage(
                    content=full_response,
                    additional_kwargs={"timestamp": timestamp}
                ))
            
        except Exception as e:
            print(f"âŒ Agent æµå¼å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            yield "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
    
    def _retrieve_for_agent(self, query: str) -> str:
        """Agent å†…éƒ¨ä½¿ç”¨çš„æ£€ç´¢æ–¹æ³•"""
        results = self.milvus_store.search_similar(self.agent_name, query, top_k=2)
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"
        return "\n\n".join(r["content"] for r in results[:2])
    
    def add_document(self, file_path: str) -> dict:
        """
        æ·»åŠ æ–‡æ¡£åˆ° Milvus
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            dict: å¤„ç†ç»“æœ
        """
        try:
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            filename = os.path.basename(file_path)
            file_size = os.path.getsize(file_path)
            file_id = str(uuid.uuid4())
            
            print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {filename}")
            
            # åŠ è½½æ–‡æ¡£
            if file_path.endswith('.pdf'):
                loader = PyPDFLoader(file_path)
                docs = loader.load()
            elif file_path.endswith(('.txt', '.md')):
                # å°è¯•å¤šç§ç¼–ç åŠ è½½æ–‡æœ¬æ–‡ä»¶
                docs = None
                encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'latin-1']
                
                for encoding in encodings:
                    try:
                        loader = TextLoader(file_path, encoding=encoding)
                        docs = loader.load()
                        print(f"  ä½¿ç”¨ {encoding} ç¼–ç åŠ è½½æˆåŠŸ")
                        break
                    except Exception as e:
                        continue
                
                if docs is None:
                    raise ValueError(f"æ— æ³•åŠ è½½æ–‡ä»¶ï¼Œå°è¯•äº†æ‰€æœ‰ç¼–ç : {encodings}")
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
            
            print(f"  åŠ è½½äº† {len(docs)} ä¸ªæ–‡æ¡£é¡µ")
            
            # åˆ†å‰²æ–‡æœ¬
            # æ³¨æ„ï¼šEmbedding API é™åˆ¶æ¯ä¸ªæ–‡æœ¬ < 512 tokens
            # å¯¹äºä¸­æ–‡ï¼Œ1ä¸ªæ±‰å­—çº¦ç­‰äº2ä¸ªtokensï¼Œæ‰€ä»¥ chunk_size è®¾ä¸º 400 å­—ç¬¦æ¯”è¾ƒå®‰å…¨
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=800,
                chunk_overlap=120,
                add_start_index=True,
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ï¼Œ", " "]
            )
            splits = text_splitter.split_documents(docs)
            print(f"  åˆ†å‰²ä¸º {len(splits)} ä¸ªæ–‡æœ¬å—")
            
            # è¿‡æ»¤å’Œæˆªæ–­è¿‡é•¿çš„æ–‡æœ¬å—ï¼ˆEmbedding API é™åˆ¶ < 512 tokensï¼‰
            # å¯¹äºä¸­æ–‡ï¼Œç²—ç•¥ä¼°è®¡ 1ä¸ªæ±‰å­— â‰ˆ 2 tokensï¼Œæ‰€ä»¥é™åˆ¶åœ¨ 250 å­—ç¬¦ä»¥å†…
            filtered_splits = []
            for split in splits:
                content = split.page_content
                if len(content) > 250:
                    # æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬
                    split.page_content = content[:250] + "..."
                filtered_splits.append(split)
            
            print(f"  è¿‡æ»¤åä¿ç•™ {len(filtered_splits)} ä¸ªæ–‡æœ¬å—")
            
            # æ·»åŠ å…ƒæ•°æ®
            for split in filtered_splits:
                split.metadata.update({
                    'file_id': file_id,
                    'filename': filename,
                    'agent_name': self.agent_name
                })
            
            # æ‰¹é‡æ·»åŠ åˆ° Milvus
            # æ³¨æ„ï¼šEmbedding API æ‰¹æ¬¡å¤§å°é™åˆ¶ä¸º 32
            batch_size = 32
            total_added = 0
            failed_batches = []
            
            for i in range(0, len(filtered_splits), batch_size):
                batch = filtered_splits[i:i + batch_size]
                try:
                    self.vector_store.add_documents(batch)
                    total_added += len(batch)
                    print(f"  è¿›åº¦: {total_added}/{len(filtered_splits)}")
                except Exception as e:
                    error_msg = str(e)
                    print(f"  âš ï¸ æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: {error_msg}")
                    failed_batches.append((i//batch_size + 1, error_msg))
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡æˆåŠŸæ·»åŠ 
            if total_added == 0:
                error_details = "\n".join([f"æ‰¹æ¬¡{batch}: {err}" for batch, err in failed_batches])
                raise Exception(
                    f"å‘é‡åŒ–å¤±è´¥ï¼šæ‰€æœ‰æ–‡æœ¬å—éƒ½æœªèƒ½æ·»åŠ åˆ°å‘é‡æ•°æ®åº“ã€‚\n"
                    f"å¯èƒ½åŸå› ï¼š\n"
                    f"1. Embedding API é…ç½®é”™è¯¯æˆ– API Key æ— æ•ˆ\n"
                    f"2. ç½‘ç»œè¿æ¥é—®é¢˜\n"
                    f"3. å‘é‡æ•°æ®åº“è¿æ¥å¼‚å¸¸\n"
                    f"è¯¦ç»†é”™è¯¯ï¼š\n{error_details}"
                )
            
            print(f"âœ… æˆåŠŸæ·»åŠ  {total_added}/{len(filtered_splits)} ä¸ªå‘é‡")
            if failed_batches:
                print(f"âš ï¸ å¤±è´¥ {len(failed_batches)} ä¸ªæ‰¹æ¬¡")
            
            # ä¿å­˜å…ƒæ•°æ®
            files_meta = self._load_files_meta()
            files_meta.append({
                'id': file_id,
                'filename': filename,
                'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'file_size': file_size,
                'chunks_count': total_added,
                'file_type': file_path.split('.')[-1]
            })
            self._save_files_meta(files_meta)
            
            # åˆ é™¤æºæ–‡ä»¶
            try:
                os.remove(file_path)
                print(f"ğŸ—‘ï¸ æºæ–‡ä»¶å·²åˆ é™¤")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤æºæ–‡ä»¶å¤±è´¥: {e}")
            
            return {
                'file_id': file_id,
                'filename': filename,
                'chunks_count': total_added
            }
            
        except Exception as e:
            print(f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def remove_document(self, file_id: str):
        """
        ä» Milvus åˆ é™¤æ–‡æ¡£ï¼ˆåŒæ—¶åˆ é™¤å‘é‡æ•°æ®å’Œå…ƒæ•°æ®ï¼‰
        
        Args:
            file_id: æ–‡ä»¶ID
        """
        try:
            # 1. å…ˆåˆ é™¤ Milvus å‘é‡æ•°æ®ï¼ˆå…³é”®ï¼šç¡®ä¿çº§è”åˆ é™¤ï¼‰
            delete_success = self.milvus_store.delete_by_file_id(self.agent_name, file_id)
            
            if not delete_success:
                print(f"âš ï¸ å‘é‡æ•°æ®åˆ é™¤å¤±è´¥æˆ–ä¸å­˜åœ¨: {file_id}")
            
            # 2. å†æ›´æ–°å…ƒæ•°æ®
            files_meta = self._load_files_meta()
            original_count = len(files_meta)
            files_meta = [f for f in files_meta if f['id'] != file_id]
            
            if len(files_meta) == original_count:
                print(f"âš ï¸ å…ƒæ•°æ®ä¸­æœªæ‰¾åˆ°æ–‡ä»¶: {file_id}")
            
            self._save_files_meta(files_meta)
            
            print(f"âœ… æ–‡æ¡£å·²å®Œå…¨åˆ é™¤: {file_id} (å‘é‡: {'æ˜¯' if delete_success else 'å¦'}, å…ƒæ•°æ®: {'æ˜¯' if len(files_meta) < original_count else 'å¦'})")
        except Exception as e:
            print(f"âŒ åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def get_files_meta(self) -> List[dict]:
        """è·å–æ–‡ä»¶å…ƒæ•°æ®"""
        return self._load_files_meta()
    
    def _load_files_meta(self) -> List[dict]:
        """åŠ è½½å…ƒæ•°æ®"""
        if os.path.exists(self.files_meta_path):
            try:
                with open(self.files_meta_path, 'r', encoding='utf-8') as f:
                    return json.load(f).get('files', [])
            except:
                return []
        return []
    
    def _save_files_meta(self, files: List[dict]):
        """ä¿å­˜å…ƒæ•°æ®"""
        with open(self.files_meta_path, 'w', encoding='utf-8') as f:
            json.dump({'files': files}, f, ensure_ascii=False, indent=2)
    
    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.chat_history = []
        print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…é™¤")
    
    def update_system_prompt(self, new_prompt: str):
        """æ›´æ–°ç³»ç»Ÿæç¤ºè¯"""
        self.system_prompt = new_prompt
        self._create_agent()
        print(f"âœ… ç³»ç»Ÿæç¤ºè¯å·²æ›´æ–°: {self.agent_name}")
    
    def get_system_prompt(self) -> str:
        """è·å–å½“å‰ç³»ç»Ÿæç¤ºè¯"""
        return self.system_prompt
