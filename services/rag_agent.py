"""
RAG Agent - åŸºäº Milvus çš„æ™ºèƒ½é—®ç­”ä»£ç†
ä½¿ç”¨ LangChain v1.0+ Agent æ¡†æ¶å®ç°
"""
import os
import json
import uuid
from datetime import datetime
from typing import Optional, List
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain.agents import create_agent
from langchain_core.tools import tool
from langchain_core.tools import StructuredTool
from services.milvus_service import get_milvus_store

load_dotenv()


class RAGAgent:
    """åŸºäº Milvus çš„ RAG Agent"""
    
    def __init__(self, agent_name: str, system_prompt: str):
        """
        åˆå§‹åŒ– RAG Agent
        
        Args:
            agent_name: æ™ºèƒ½ä½“åç§°
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¿…å¡«ï¼‰
        
        Raises:
            ValueError: å¦‚æœ system_prompt ä¸ºç©º
        """
        if not system_prompt or not system_prompt.strip():
            raise ValueError("system_prompt ä¸èƒ½ä¸ºç©ºï¼Œå¿…é¡»æä¾›æœ‰æ•ˆçš„ç³»ç»Ÿæç¤ºè¯")
        
        self.agent_name = agent_name
        self.system_prompt = system_prompt.strip()
        self.milvus_store = get_milvus_store()
        self.vector_store = None
        self.agent = None
        self.chat_history = []
        
        # å…ƒæ•°æ®è·¯å¾„
        self.metadata_dir = os.getenv("METADATA_DIR", "metadata_store")
        os.makedirs(self.metadata_dir, exist_ok=True)
        self.files_meta_path = os.path.join(self.metadata_dir, f"{agent_name}.json")
        
        # åˆå§‹åŒ–
        self._init_vector_store()
        self._create_agent()
    
    def _init_vector_store(self):
        """åˆå§‹åŒ–å‘é‡å­˜å‚¨"""
        self.vector_store = self.milvus_store.get_vector_store(self.agent_name)
        print(f"âœ… å‘é‡å­˜å‚¨å·²å°±ç»ª: {self.agent_name}")
    
    def _create_agent(self):
        """ä½¿ç”¨ LangChain v1.0+ Agent æ¡†æ¶åˆ›å»º Agent"""
        # 1. åˆ›å»º LLM
        model = ChatOpenAI(
            temperature=0,
            max_tokens=1000,
            model=os.getenv("CHAT_MODEL", "gpt-3.5-turbo"),
            base_url=os.getenv("OPENAI_BASE_URL"),
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # 2. ä½¿ç”¨ @tool è£…é¥°å™¨å®šä¹‰å·¥å…·ï¼ˆLangChain v1.0+ æ ‡å‡†æ–¹å¼ï¼‰
        agent_name = self.agent_name  # é—­åŒ…æ•è·
        milvus_store = self.milvus_store
        
        @tool
        def knowledge_base_search(query: str) -> str:
            """æœç´¢æ™ºèƒ½ä½“çš„çŸ¥è¯†åº“è·å–ç›¸å…³æ–‡æ¡£å†…å®¹ã€‚
            
            è¿™ä¸ªå·¥å…·çš„åŠŸèƒ½æ˜¯æŸ¥æ‰¾åŸå§‹èµ„æ–™ï¼Œç”¨äºå›ç­”ç”¨æˆ·æå‡ºçš„**æ‰€æœ‰äº‹å®æ€§é—®é¢˜**ã€‚
            
            **[é€šç”¨æ£€ç´¢æŒ‡å—]**ï¼šå¦‚æœç”¨æˆ·çš„æŸ¥è¯¢éœ€è¦**ç²¾ç¡®äº‹å®ã€ç‰¹å®šèº«ä»½ã€æˆ–è·¨ä¸Šä¸‹æ–‡çš„å®šä¹‰**ï¼Œä½ åº”è¯¥å°è¯•ä½¿ç”¨åŒ…å«**å¤šä¸ªè§’åº¦æˆ–åŒä¹‰è¯**çš„å…³é”®è¯è¿›è¡Œæœç´¢ï¼Œä»¥æé«˜å…¨é¢å¬å›ç‡ã€‚
            
            ä½ éœ€è¦é˜…è¯»å·¥å…·è¿”å›çš„æ‰€æœ‰åŸå§‹æ–‡æ¡£ï¼Œå¹¶æå–å…³é”®ä¿¡æ¯ï¼Œç”¨è‡ªç„¶çš„è¯­è¨€ç»„ç»‡æˆæœ€ç»ˆç­”æ¡ˆã€‚
            
            Args:
                query: æœç´¢æŸ¥è¯¢ï¼ˆç”¨æˆ·é—®é¢˜æˆ–å…³é”®è¯ï¼Œè¯·ç¡®ä¿æŸ¥è¯¢è¯èƒ½æœ€å¤§é™åº¦åœ°è¦†ç›–çŸ¥è¯†åº“ä¸­çš„ç›¸å…³ä¿¡æ¯ï¼‰
                
            Returns:
                åŸå§‹æ–‡æ¡£å†…å®¹ï¼ˆéœ€è¦ä½ è¿›ä¸€æ­¥å¤„ç†å’Œæ€»ç»“ï¼‰
            """
            results = milvus_store.search_similar(agent_name, query, top_k=3)
            if not results:
                return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"
            
            # ç®€æ´è¿”å›ï¼Œä¸åŠ ä»»ä½•"æ–‡æ¡£ç‰‡æ®µ"æ ‡ç­¾
            return "\n\n".join(r['content'] for r in results[:3])


        # å®šä¹‰æ£€ç´¢å·¥å…·
        def retrieve_context(query: str) -> str:
            """ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³å†…å®¹"""
            # ä½¿ç”¨ similarity_search_with_score è·å–åˆ†æ•°,æé«˜ç¡®å®šæ€§
            results = self.vector_store.similarity_search_with_score(query, k=3)
            
            # æŒ‰åˆ†æ•°æ’åº(åˆ†æ•°è¶Šä½è¶Šç›¸ä¼¼)
            results_sorted = sorted(results, key=lambda x: x[1])
            
            # åªä½¿ç”¨å‰2ä¸ªæœ€ç›¸å…³çš„ç»“æœ
            retrieved_docs = [doc for doc, score in results_sorted[:2]]
            
            serialized = "\n\n".join(
                f"Content: {doc.page_content}"
                for doc in retrieved_docs
            )
            return serialized
        
        retrieve_tool = StructuredTool.from_function(
            func=retrieve_context,
            name="retrieve_context",
            description="æ ¹æ®ç”¨æˆ·é—®é¢˜,ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹ã€‚",
        )
        
        tools = [retrieve_tool]
        
        #tools = [knowledge_base_search]
        
        # 3. ä½¿ç”¨ create_agentï¼ˆLangChain v1.0+ å®˜æ–¹æ¨è APIï¼‰
        self.agent = create_agent(
            model=model,
            tools=tools,
            system_prompt=self.system_prompt,
        )
        
        print(f"âœ… LangChain v1.0+ Agent åˆ›å»ºæˆåŠŸ (create_agent): {self.agent_name} and system_prompt ({self.system_prompt})")
    
    def ask(self, question: str) -> str:
        """
        å‘ Agent æé—®ï¼ˆä½¿ç”¨ LangChain v1.0+ create_agentï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            str: Agent å›ç­”
        """
        try:
            # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦ä¸ºç©º
            stats = self.milvus_store.get_collection_stats(self.agent_name)
            if stats and stats.get("total_vectors", 0) == 0:
                empty_kb_msg = "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚ç›®å‰æˆ‘çš„çŸ¥è¯†åº“è¿˜æ˜¯ç©ºçš„ï¼Œè¯·ç®¡ç†å‘˜å…ˆä¸Šä¼ ç›¸å…³æ–‡æ¡£ï¼Œæˆ‘æ‰èƒ½æ›´å¥½åœ°ä¸ºæ‚¨æœåŠ¡ã€‚"
                return empty_kb_msg
            
            # æ„å»ºæ¶ˆæ¯å†å²ï¼ˆLangGraph State æ ¼å¼ï¼‰
            messages = []
            # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆä¿ç•™æœ€è¿‘10è½®ï¼‰
            messages.extend(self.chat_history[-10:])
            # æ·»åŠ å½“å‰ç”¨æˆ·é—®é¢˜
            messages.append({"role": "user", "content": question})
            
            # ä½¿ç”¨ Agent æ‰§è¡Œï¼ˆLangGraph APIï¼‰
            result = self.agent.invoke({"messages": messages})
            
            # æå–æœ€åä¸€æ¡ AI æ¶ˆæ¯
            final_messages = result.get("messages", [])
            if final_messages:
                answer = final_messages[-1].content
            else:
                answer = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
            
            # æ›´æ–°å¯¹è¯å†å²ï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼‰
            import time
            timestamp = int(time.time())  # Unix æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            
            self.chat_history.append(HumanMessage(
                content=question,
                additional_kwargs={"timestamp": timestamp}
            ))
            self.chat_history.append(AIMessage(
                content=answer,
                additional_kwargs={"timestamp": timestamp}
            ))
            
            return answer
            
        except Exception as e:
            print(f"âŒ Agent å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
    
    async def ask_stream(self, question: str):
        """
        å‘ Agent æé—®ï¼ˆæµå¼å“åº”ï¼ŒLangChain v1.0+ create_agentï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Yields:
            str: é€å—è¿”å›çš„å›ç­”å†…å®¹
        """
        try:
            # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦ä¸ºç©º
            stats = self.milvus_store.get_collection_stats(self.agent_name)
            if stats and stats.get("total_vectors", 0) == 0:
                empty_kb_msg = "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚ç›®å‰æˆ‘çš„çŸ¥è¯†åº“è¿˜æ˜¯ç©ºçš„ï¼Œè¯·ç®¡ç†å‘˜å…ˆä¸Šä¼ ç›¸å…³æ–‡æ¡£ï¼Œæˆ‘æ‰èƒ½æ›´å¥½åœ°ä¸ºæ‚¨æœåŠ¡ã€‚"
                yield empty_kb_msg
                return
            
            # æ„å»ºæ¶ˆæ¯å†å²
            messages = []
            messages.extend(self.chat_history[-10:])
            messages.append({"role": "user", "content": question})
            
            # Agent æµå¼å“åº”ï¼ˆLangGraph stream APIï¼‰
            full_response = ""
            last_content_length = 0
            
            async for chunk in self.agent.astream(
                {"messages": messages},
                stream_mode="values"  # æµå¼è¾“å‡ºçŠ¶æ€å€¼
            ):
                # è·å–æœ€æ–°æ¶ˆæ¯
                latest_messages = chunk.get("messages", [])
                if latest_messages:
                    latest_message = latest_messages[-1]
                    
                    # å¦‚æœæ˜¯ AI æ¶ˆæ¯ï¼Œæµå¼è¾“å‡ºå†…å®¹
                    if hasattr(latest_message, "content") and latest_message.content:
                        content = latest_message.content
                        # åªè¾“å‡ºæ–°å¢çš„å†…å®¹ï¼ˆå¢é‡è¾“å‡ºï¼‰
                        if len(content) > last_content_length:
                            new_content = content[last_content_length:]
                            last_content_length = len(content)
                            full_response = content
                            yield new_content
                    
                    # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼Œæ‰“å°æ—¥å¿—
                    elif hasattr(latest_message, "tool_calls") and latest_message.tool_calls:
                        for tc in latest_message.tool_calls:
                            print(f"ğŸ”§ Agent æ­£åœ¨ä½¿ç”¨å·¥å…·: {tc.get('name', 'unknown')}")
            
            # æ›´æ–°å¯¹è¯å†å²ï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼‰
            if full_response:
                import time
                timestamp = int(time.time())  # Unix æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
                
                self.chat_history.append(HumanMessage(
                    content=question,
                    additional_kwargs={"timestamp": timestamp}
                ))
                self.chat_history.append(AIMessage(
                    content=full_response,
                    additional_kwargs={"timestamp": timestamp}
                ))
            
        except Exception as e:
            print(f"âŒ Agent æµå¼å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            yield "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
    
    def add_document(self, file_path: str) -> dict:
        """
        æ·»åŠ æ–‡æ¡£åˆ° Milvus
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            dict: å¤„ç†ç»“æœ
        """
        # æå‰ç”Ÿæˆ file_id å’Œ filenameï¼Œç¡®ä¿å¤±è´¥æ—¶ä¹Ÿèƒ½è®°å½•
        file_id = str(uuid.uuid4())
        filename = os.path.basename(file_path) if file_path else "unknown"
        
        try:
            # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
            if not os.path.exists(file_path):
                # å³ä½¿æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿå…ˆåˆ›å»ºå…ƒæ•°æ®æ¡ç›®ï¼Œè¿™æ ·å¯ä»¥è®°å½•å¤±è´¥çŠ¶æ€
                self._save_initial_metadata(file_id, filename, 0, file_path)
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            filename = os.path.basename(file_path)
            file_size = os.path.getsize(file_path)
            
            print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {filename}")
            
            # 1ï¸âƒ£ ç«‹å³ä¿å­˜åˆå§‹å…ƒæ•°æ®ï¼ˆstatus=processingï¼‰
            self._save_initial_metadata(file_id, filename, file_size, file_path)
            
            # åŠ è½½æ–‡æ¡£
            if file_path.endswith('.pdf'):
                loader = PyPDFLoader(file_path)
                docs = loader.load()
            elif file_path.endswith(('.txt', '.md')):
                # å°è¯•å¤šç§ç¼–ç åŠ è½½æ–‡æœ¬æ–‡ä»¶
                docs = None
                encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'latin-1']
                
                for encoding in encodings:
                    try:
                        loader = TextLoader(file_path, encoding=encoding)
                        docs = loader.load()
                        print(f"  ä½¿ç”¨ {encoding} ç¼–ç åŠ è½½æˆåŠŸ")
                        break
                    except Exception as e:
                        continue
                
                if docs is None:
                    raise ValueError(f"æ— æ³•åŠ è½½æ–‡ä»¶ï¼Œå°è¯•äº†æ‰€æœ‰ç¼–ç : {encodings}")
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
            
            print(f"  åŠ è½½äº† {len(docs)} ä¸ªæ–‡æ¡£é¡µ")
            
            # åˆ†å‰²æ–‡æœ¬
            # æ³¨æ„ï¼šEmbedding API é™åˆ¶æ¯ä¸ªæ–‡æœ¬ < 512 tokens
            # å¯¹äºä¸­æ–‡ï¼Œ1ä¸ªæ±‰å­—çº¦ç­‰äº2ä¸ªtokensï¼Œæ‰€ä»¥ chunk_size è®¾ä¸º 400 å­—ç¬¦æ¯”è¾ƒå®‰å…¨
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=800,
                chunk_overlap=120,
                add_start_index=True,
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ï¼Œ", " "]
            )
            splits = text_splitter.split_documents(docs)
            print(f"  åˆ†å‰²ä¸º {len(splits)} ä¸ªæ–‡æœ¬å—")
            
            # è¿‡æ»¤å’Œæˆªæ–­è¿‡é•¿çš„æ–‡æœ¬å—ï¼ˆEmbedding API é™åˆ¶ < 512 tokensï¼‰
            # å¯¹äºä¸­æ–‡ï¼Œç²—ç•¥ä¼°è®¡ 1ä¸ªæ±‰å­— â‰ˆ 2 tokensï¼Œæ‰€ä»¥é™åˆ¶åœ¨ 250 å­—ç¬¦ä»¥å†…
            filtered_splits = []
            for split in splits:
                content = split.page_content
                if len(content) > 250:
                    # æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬
                    split.page_content = content[:250] + "..."
                filtered_splits.append(split)
            
            print(f"  è¿‡æ»¤åä¿ç•™ {len(filtered_splits)} ä¸ªæ–‡æœ¬å—")
            
            # æ·»åŠ å…ƒæ•°æ®
            for split in filtered_splits:
                split.metadata.update({
                    'file_id': file_id,
                    'filename': filename,
                    'agent_name': self.agent_name
                })
            
            # æ‰¹é‡æ·»åŠ åˆ° Milvus
            # æ³¨æ„ï¼šEmbedding API æ‰¹æ¬¡å¤§å°é™åˆ¶ä¸º 32
            batch_size = 32
            total_added = 0
            failed_batches = []
            
            for i in range(0, len(filtered_splits), batch_size):
                batch = filtered_splits[i:i + batch_size]
                try:
                    self.vector_store.add_documents(batch)
                    total_added += len(batch)
                    print(f"  è¿›åº¦: {total_added}/{len(filtered_splits)}")
                except Exception as e:
                    error_msg = str(e)
                    print(f"  âš ï¸ æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: {error_msg}")
                    failed_batches.append((i//batch_size + 1, error_msg))
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡æˆåŠŸæ·»åŠ 
            if total_added == 0:
                error_details = "\n".join([f"æ‰¹æ¬¡{batch}: {err}" for batch, err in failed_batches])
                raise Exception(
                    f"å‘é‡åŒ–å¤±è´¥ï¼šæ‰€æœ‰æ–‡æœ¬å—éƒ½æœªèƒ½æ·»åŠ åˆ°å‘é‡æ•°æ®åº“ã€‚\n"
                    f"å¯èƒ½åŸå› ï¼š\n"
                    f"1. Embedding API é…ç½®é”™è¯¯æˆ– API Key æ— æ•ˆ\n"
                    f"2. ç½‘ç»œè¿æ¥é—®é¢˜\n"
                    f"3. å‘é‡æ•°æ®åº“è¿æ¥å¼‚å¸¸\n"
                    f"è¯¦ç»†é”™è¯¯ï¼š\n{error_details}"
                )
            
            print(f"âœ… æˆåŠŸæ·»åŠ  {total_added}/{len(filtered_splits)} ä¸ªå‘é‡")
            if failed_batches:
                print(f"âš ï¸ å¤±è´¥ {len(failed_batches)} ä¸ªæ‰¹æ¬¡")
            
            # 2ï¸âƒ£ æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆï¼ˆreadyï¼‰
            self._update_file_status(
                file_id=file_id,
                status='ready',
                processing_progress=100,
                chunks_count=total_added
            )
            
            # åˆ é™¤æºæ–‡ä»¶
            try:
                os.remove(file_path)
                print(f"ğŸ—‘ï¸ æºæ–‡ä»¶å·²åˆ é™¤")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤æºæ–‡ä»¶å¤±è´¥: {e}")
            
            return {
                'file_id': file_id,
                'filename': filename,
                'chunks_count': total_added,
                'status': 'ready',  # âœ… æ–°å¢
                'processing_progress': 100  # âœ… æ–°å¢
            }
            
        except Exception as e:
            print(f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            # 3ï¸âƒ£ å¤±è´¥æ—¶æ›´æ–°çŠ¶æ€
            try:
                self._update_file_status(
                    file_id=file_id,
                    status='failed',
                    processing_progress=0,
                    error_message=str(e)
                )
            except:
                pass  # å¦‚æœå…ƒæ•°æ®æ›´æ–°å¤±è´¥ï¼Œä¸å½±å“å¼‚å¸¸æŠ›å‡º
            raise
    
    def remove_document(self, file_id: str):
        """
        ä» Milvus åˆ é™¤æ–‡æ¡£ï¼ˆåŒæ—¶åˆ é™¤å‘é‡æ•°æ®å’Œå…ƒæ•°æ®ï¼‰
        
        Args:
            file_id: æ–‡ä»¶ID
        """
        try:
            # 1. å…ˆåˆ é™¤ Milvus å‘é‡æ•°æ®ï¼ˆå…³é”®ï¼šç¡®ä¿çº§è”åˆ é™¤ï¼‰
            delete_success = self.milvus_store.delete_by_file_id(self.agent_name, file_id)
            
            if not delete_success:
                print(f"âš ï¸ å‘é‡æ•°æ®åˆ é™¤å¤±è´¥æˆ–ä¸å­˜åœ¨: {file_id}")
            
            # 2. å†æ›´æ–°å…ƒæ•°æ®
            files_meta = self._load_files_meta()
            original_count = len(files_meta)
            files_meta = [f for f in files_meta if f['id'] != file_id]
            
            if len(files_meta) == original_count:
                print(f"âš ï¸ å…ƒæ•°æ®ä¸­æœªæ‰¾åˆ°æ–‡ä»¶: {file_id}")
            
            self._save_files_meta(files_meta)
            
            print(f"âœ… æ–‡æ¡£å·²å®Œå…¨åˆ é™¤: {file_id} (å‘é‡: {'æ˜¯' if delete_success else 'å¦'}, å…ƒæ•°æ®: {'æ˜¯' if len(files_meta) < original_count else 'å¦'})")
        except Exception as e:
            print(f"âŒ åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def get_files_meta(self) -> List[dict]:
        """è·å–æ–‡ä»¶å…ƒæ•°æ®"""
        return self._load_files_meta()
    
    def _load_files_meta(self) -> List[dict]:
        """åŠ è½½å…ƒæ•°æ®"""
        if os.path.exists(self.files_meta_path):
            try:
                with open(self.files_meta_path, 'r', encoding='utf-8') as f:
                    return json.load(f).get('files', [])
            except:
                return []
        return []
    
    def _save_files_meta(self, files: List[dict]):
        """ä¿å­˜å…ƒæ•°æ®"""
        with open(self.files_meta_path, 'w', encoding='utf-8') as f:
            json.dump({'files': files}, f, ensure_ascii=False, indent=2)
    
    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.chat_history = []
        print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…é™¤")
    
    def update_system_prompt(self, new_prompt: str):
        """æ›´æ–°ç³»ç»Ÿæç¤ºè¯"""
        self.system_prompt = new_prompt
        self._create_agent()
        print(f"âœ… ç³»ç»Ÿæç¤ºè¯å·²æ›´æ–°: {self.agent_name}")
    
    def get_system_prompt(self) -> str:
        """è·å–å½“å‰ç³»ç»Ÿæç¤ºè¯"""
        return self.system_prompt
    
    def _save_initial_metadata(self, file_id: str, filename: str, file_size: int, file_path: str):
        """ä¿å­˜åˆå§‹æ–‡ä»¶å…ƒæ•°æ®ï¼ˆstatus=processingï¼‰"""
        files_meta = self._load_files_meta()
        files_meta.append({
            'id': file_id,
            'filename': filename,
            'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'file_size': file_size,
            'chunks_count': 0,
            'file_type': file_path.split('.')[-1],
            'status': 'processing',  # âœ… åˆå§‹çŠ¶æ€
            'error_message': None,  # âœ… æ–°å¢
            'processing_progress': 0,  # âœ… æ–°å¢
            'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # âœ… æ–°å¢
        })
        self._save_files_meta(files_meta)
        print(f"ğŸ“ åˆå§‹å…ƒæ•°æ®å·²ä¿å­˜: {filename} (status=processing)")
    
    def _update_file_status(self, file_id: str, status: str, processing_progress: int,
                           chunks_count: int = None, error_message: str = None):
        """æ›´æ–°æ–‡ä»¶å¤„ç†çŠ¶æ€"""
        files_meta = self._load_files_meta()
        
        for file in files_meta:
            if file['id'] == file_id:
                file['status'] = status
                file['processing_progress'] = processing_progress
                file['updated_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                if chunks_count is not None:
                    file['chunks_count'] = chunks_count
                if error_message:
                    file['error_message'] = error_message
                
                self._save_files_meta(files_meta)
                print(f"ğŸ“ çŠ¶æ€å·²æ›´æ–°: {file['filename']} -> {status} ({processing_progress}%)")
                return
        
        print(f"âš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶å…ƒæ•°æ®: {file_id}")
