"""
RAG Agent - åŸºäº Milvus çš„æ™ºèƒ½é—®ç­”ä»£ç†
"""
import os
import json
import uuid
from datetime import datetime
from typing import Optional, List
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from services.milvus_service import get_milvus_store

load_dotenv()


class RAGAgent:
    """åŸºäº Milvus çš„ RAG Agent"""
    
    def __init__(self, agent_name: str, system_prompt: str = None):
        """
        åˆå§‹åŒ– RAG Agent
        
        Args:
            agent_name: æ™ºèƒ½ä½“åç§°
            system_prompt: ç³»ç»Ÿæç¤ºè¯
        """
        self.agent_name = agent_name
        self.system_prompt = system_prompt or self._get_default_prompt()
        self.milvus_store = get_milvus_store()
        self.vector_store = None
        self.agent = None
        self.chat_history = []
        
        # å…ƒæ•°æ®è·¯å¾„
        self.metadata_dir = os.getenv("METADATA_DIR", "metadata_store")
        os.makedirs(self.metadata_dir, exist_ok=True)
        self.files_meta_path = os.path.join(self.metadata_dir, f"{agent_name}.json")
        
        # åˆå§‹åŒ–
        self._init_vector_store()
        self._create_agent()
    
    def _get_default_prompt(self) -> str:
        """è·å–é»˜è®¤ç³»ç»Ÿæç¤ºè¯"""
        return (
            "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥åŸºäºçŸ¥è¯†åº“å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n"
            "é‡è¦è§„åˆ™:\n"
            "1. ä½¿ç”¨æ£€ç´¢åˆ°çš„çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ï¼Œå‡†ç¡®å¼•ç”¨ç›¸å…³ä¿¡æ¯\n"
            "2. å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œè¯šå®å‘ŠçŸ¥ç”¨æˆ·\n"
            "3. ä½¿ç”¨æ¸…æ™°æ˜“æ‡‚çš„è¯­è¨€ç»„ç»‡ç­”æ¡ˆ\n"
            "4. å¯¹äºç›¸åŒçš„é—®é¢˜ï¼Œå§‹ç»ˆç»™å‡ºä¸€è‡´çš„ç­”æ¡ˆ"
        )
    
    def _init_vector_store(self):
        """åˆå§‹åŒ–å‘é‡å­˜å‚¨"""
        self.vector_store = self.milvus_store.get_vector_store(self.agent_name)
        print(f"âœ… å‘é‡å­˜å‚¨å·²å°±ç»ª: {self.agent_name}")
    
    def _create_agent(self):
        """åˆ›å»ºç®€åŒ–çš„ LLMï¼ˆä¸ä½¿ç”¨ Agent æ¡†æ¶ï¼‰"""
        # åˆ›å»º LLM
        self.llm = ChatOpenAI(
            temperature=0,
            max_tokens=1000,
            model=os.getenv("CHAT_MODEL", "gpt-3.5-turbo"),
            base_url=os.getenv("OPENAI_BASE_URL"),
            api_key=os.getenv("OPENAI_API_KEY")
        )
        print(f"âœ… LLM åˆ›å»ºæˆåŠŸ: {self.agent_name}")
    
    def ask(self, question: str) -> str:
        """
        å‘ Agent æé—®ï¼ˆåŒæ­¥æ–¹å¼ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            str: Agent çš„å›ç­”
        """
        try:
            self.chat_history.append(HumanMessage(content=question))
            
            # ä»çŸ¥è¯†åº“æ£€ç´¢
            context = self._retrieve_for_agent(question)
            
            # æ„å»º Prompt
            prompt_text = f"{self.system_prompt}\n\nçŸ¥è¯†åº“å†…å®¹ï¼š\n{context}\n\nç”¨æˆ·é—®é¢˜ï¼š{question}\n\nè¯·åŸºäºçŸ¥è¯†åº“å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
            
            # è°ƒç”¨ LLM
            response = self.llm.invoke(prompt_text)
            answer = response.content if hasattr(response, 'content') else str(response)
            
            self.chat_history.append(AIMessage(content=answer))
            return answer
            
        except Exception as e:
            print(f"âŒ å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
            self.chat_history.append(AIMessage(content=error_msg))
            return error_msg
    
    async def ask_stream(self, question: str):
        """
        å‘ Agent æé—®ï¼ˆæµå¼å“åº”ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Yields:
            str: é€å—è¿”å›çš„å›ç­”å†…å®¹
        """
        try:
            self.chat_history.append(HumanMessage(content=question))
            
            # ä»çŸ¥è¯†åº“æ£€ç´¢
            context = self._retrieve_for_agent(question)
            
            # æ„å»º Prompt
            prompt_text = f"{self.system_prompt}\n\nçŸ¥è¯†åº“å†…å®¹ï¼š\n{context}\n\nç”¨æˆ·é—®é¢˜ï¼š{question}\n\nè¯·åŸºäºçŸ¥è¯†åº“å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
            
            # æµå¼è°ƒç”¨ LLM
            full_response = ""
            async for chunk in self.llm.astream(prompt_text):
                if hasattr(chunk, 'content') and chunk.content:
                    content = chunk.content
                    full_response += content
                    yield content
            
            # ä¿å­˜å®Œæ•´å›ç­”åˆ°å†å²
            self.chat_history.append(AIMessage(content=full_response))
            
        except Exception as e:
            print(f"âŒ æµå¼å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            error_msg = "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
            self.chat_history.append(AIMessage(content=error_msg))
            yield error_msg
    
    def _retrieve_for_agent(self, query: str) -> str:
        """Agent å†…éƒ¨ä½¿ç”¨çš„æ£€ç´¢æ–¹æ³•"""
        results = self.milvus_store.search_similar(self.agent_name, query, top_k=2)
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"
        return "\n\n".join(r["content"] for r in results[:2])
    
    def add_document(self, file_path: str) -> dict:
        """
        æ·»åŠ æ–‡æ¡£åˆ° Milvus
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            dict: å¤„ç†ç»“æœ
        """
        try:
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            filename = os.path.basename(file_path)
            file_size = os.path.getsize(file_path)
            file_id = str(uuid.uuid4())
            
            print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {filename}")
            
            # åŠ è½½æ–‡æ¡£
            if file_path.endswith('.pdf'):
                loader = PyPDFLoader(file_path)
            elif file_path.endswith(('.txt', '.md')):
                loader = TextLoader(file_path, encoding='utf-8')
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
            
            docs = loader.load()
            print(f"  åŠ è½½äº† {len(docs)} ä¸ªæ–‡æ¡£é¡µ")
            
            # åˆ†å‰²æ–‡æœ¬
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=800,
                chunk_overlap=200,
                add_start_index=True
            )
            splits = text_splitter.split_documents(docs)
            print(f"  åˆ†å‰²ä¸º {len(splits)} ä¸ªæ–‡æœ¬å—")
            
            # æ·»åŠ å…ƒæ•°æ®
            for split in splits:
                split.metadata.update({
                    'file_id': file_id,
                    'filename': filename,
                    'agent_name': self.agent_name
                })
            
            # æ‰¹é‡æ·»åŠ åˆ° Milvus
            batch_size = 50
            total_added = 0
            
            for i in range(0, len(splits), batch_size):
                batch = splits[i:i + batch_size]
                try:
                    self.vector_store.add_documents(batch)
                    total_added += len(batch)
                    print(f"  è¿›åº¦: {total_added}/{len(splits)}")
                except Exception as e:
                    print(f"  âš ï¸ æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: {e}")
            
            print(f"âœ… æˆåŠŸæ·»åŠ  {total_added} ä¸ªå‘é‡")
            
            # ä¿å­˜å…ƒæ•°æ®
            files_meta = self._load_files_meta()
            files_meta.append({
                'id': file_id,
                'filename': filename,
                'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'file_size': file_size,
                'chunks_count': total_added,
                'file_type': file_path.split('.')[-1]
            })
            self._save_files_meta(files_meta)
            
            # åˆ é™¤æºæ–‡ä»¶
            try:
                os.remove(file_path)
                print(f"ğŸ—‘ï¸ æºæ–‡ä»¶å·²åˆ é™¤")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤æºæ–‡ä»¶å¤±è´¥: {e}")
            
            return {
                'file_id': file_id,
                'filename': filename,
                'chunks_count': total_added
            }
            
        except Exception as e:
            print(f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def remove_document(self, file_id: str):
        """
        ä» Milvus åˆ é™¤æ–‡æ¡£
        
        Args:
            file_id: æ–‡ä»¶ID
        """
        try:
            # Milvus åˆ é™¤éœ€è¦é€šè¿‡è¡¨è¾¾å¼
            # æ³¨æ„ï¼šLangChain Milvus å¯èƒ½ä¸æ”¯æŒç›´æ¥åˆ é™¤ï¼Œéœ€è¦é‡å»ºæˆ–æ‰‹åŠ¨æ“ä½œ
            print(f"âš ï¸ Milvus åˆ é™¤åŠŸèƒ½å—é™ï¼Œå»ºè®®é‡å»ºçŸ¥è¯†åº“")
            
            # æ›´æ–°å…ƒæ•°æ®
            files_meta = self._load_files_meta()
            files_meta = [f for f in files_meta if f['id'] != file_id]
            self._save_files_meta(files_meta)
            
            print(f"âœ… å·²ä»å…ƒæ•°æ®åˆ é™¤: {file_id}")
        except Exception as e:
            print(f"âŒ åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def get_files_meta(self) -> List[dict]:
        """è·å–æ–‡ä»¶å…ƒæ•°æ®"""
        return self._load_files_meta()
    
    def _load_files_meta(self) -> List[dict]:
        """åŠ è½½å…ƒæ•°æ®"""
        if os.path.exists(self.files_meta_path):
            try:
                with open(self.files_meta_path, 'r', encoding='utf-8') as f:
                    return json.load(f).get('files', [])
            except:
                return []
        return []
    
    def _save_files_meta(self, files: List[dict]):
        """ä¿å­˜å…ƒæ•°æ®"""
        with open(self.files_meta_path, 'w', encoding='utf-8') as f:
            json.dump({'files': files}, f, ensure_ascii=False, indent=2)
    
    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.chat_history = []
        print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…é™¤")
    
    def update_system_prompt(self, new_prompt: str):
        """æ›´æ–°ç³»ç»Ÿæç¤ºè¯"""
        self.system_prompt = new_prompt
        self._create_agent()
        print(f"âœ… ç³»ç»Ÿæç¤ºè¯å·²æ›´æ–°: {self.agent_name}")
    
    def get_system_prompt(self) -> str:
        """è·å–å½“å‰ç³»ç»Ÿæç¤ºè¯"""
        return self.system_prompt
