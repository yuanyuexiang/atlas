"""
RAG Agent - åŸºäº Milvus çš„æ™ºèƒ½é—®ç­”ä»£ç†
ä½¿ç”¨ LangChain v1.0+ Agent æ¡†æ¶å®ç°
èŒè´£ï¼šå¯¹è¯ç®¡ç†ã€Agent åˆ›å»ºã€å¯¹è¯å†å²ç»´æŠ¤
"""
import os
from typing import Optional, List
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain.agents import create_agent
from langchain_core.tools import tool
from langchain_core.tools import StructuredTool
from services.vector_store_manager import VectorStoreManager

load_dotenv()


class RAGAgent:
    """åŸºäº Milvus çš„ RAG Agent - çº¯å¯¹è¯é€»è¾‘"""
    
    def __init__(
        self, 
        agent_name: str, 
        system_prompt: str,
        vector_manager: VectorStoreManager
    ):
        """
        åˆå§‹åŒ– RAG Agent
        
        Args:
            agent_name: æ™ºèƒ½ä½“åç§°
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¿…å¡«ï¼‰
            vector_manager: å‘é‡å­˜å‚¨ç®¡ç†å™¨ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
        
        Raises:
            ValueError: å¦‚æœ system_prompt ä¸ºç©º
        """
        if not system_prompt or not system_prompt.strip():
            raise ValueError("system_prompt ä¸èƒ½ä¸ºç©ºï¼Œå¿…é¡»æä¾›æœ‰æ•ˆçš„ç³»ç»Ÿæç¤ºè¯")
        
        self.agent_name = agent_name
        self.system_prompt = system_prompt.strip()
        self.vector_manager = vector_manager
        self.vector_store = None
        self.agent = None
        self.chat_history = []
        
        # åˆå§‹åŒ–
        self._init_vector_store()
        self._create_agent()
    
    def _init_vector_store(self):
        """åˆå§‹åŒ–å‘é‡å­˜å‚¨"""
        self.vector_store = self.vector_manager.get_vector_store(self.agent_name)
        print(f"âœ… å‘é‡å­˜å‚¨å·²å°±ç»ª: {self.agent_name}")
    
    def _create_agent(self):
        """ä½¿ç”¨ LangChain v1.0+ Agent æ¡†æ¶åˆ›å»º Agent"""
        # 1. åˆ›å»º LLM
        model = ChatOpenAI(
            temperature=0,
            max_tokens=1000,
            model=os.getenv("CHAT_MODEL", "gpt-3.5-turbo"),
            base_url=os.getenv("OPENAI_BASE_URL"),
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # 2. ä½¿ç”¨ @tool è£…é¥°å™¨å®šä¹‰å·¥å…·ï¼ˆLangChain v1.0+ æ ‡å‡†æ–¹å¼ï¼‰
        agent_name = self.agent_name  # é—­åŒ…æ•è·
        vector_manager = self.vector_manager
        
        @tool
        def knowledge_base_search(query: str) -> str:
            """æœç´¢æ™ºèƒ½ä½“çš„çŸ¥è¯†åº“è·å–ç›¸å…³æ–‡æ¡£å†…å®¹ã€‚
            
            è¿™ä¸ªå·¥å…·çš„åŠŸèƒ½æ˜¯æŸ¥æ‰¾åŸå§‹èµ„æ–™ï¼Œç”¨äºå›ç­”ç”¨æˆ·æå‡ºçš„**æ‰€æœ‰äº‹å®æ€§é—®é¢˜**ã€‚
            
            **[é€šç”¨æ£€ç´¢æŒ‡å—]**ï¼šå¦‚æœç”¨æˆ·çš„æŸ¥è¯¢éœ€è¦**ç²¾ç¡®äº‹å®ã€ç‰¹å®šèº«ä»½ã€æˆ–è·¨ä¸Šä¸‹æ–‡çš„å®šä¹‰**ï¼Œä½ åº”è¯¥å°è¯•ä½¿ç”¨åŒ…å«**å¤šä¸ªè§’åº¦æˆ–åŒä¹‰è¯**çš„å…³é”®è¯è¿›è¡Œæœç´¢ï¼Œä»¥æé«˜å…¨é¢å¬å›ç‡ã€‚
            
            ä½ éœ€è¦é˜…è¯»å·¥å…·è¿”å›çš„æ‰€æœ‰åŸå§‹æ–‡æ¡£ï¼Œå¹¶æå–å…³é”®ä¿¡æ¯ï¼Œç”¨è‡ªç„¶çš„è¯­è¨€ç»„ç»‡æˆæœ€ç»ˆç­”æ¡ˆã€‚
            
            Args:
                query: æœç´¢æŸ¥è¯¢ï¼ˆç”¨æˆ·é—®é¢˜æˆ–å…³é”®è¯ï¼Œè¯·ç¡®ä¿æŸ¥è¯¢è¯èƒ½æœ€å¤§é™åº¦åœ°è¦†ç›–çŸ¥è¯†åº“ä¸­çš„ç›¸å…³ä¿¡æ¯ï¼‰
                
            Returns:
                åŸå§‹æ–‡æ¡£å†…å®¹ï¼ˆéœ€è¦ä½ è¿›ä¸€æ­¥å¤„ç†å’Œæ€»ç»“ï¼‰
            """
            results = vector_manager.search_similar(agent_name, query, top_k=3)
            if not results:
                return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"
            
            # ç®€æ´è¿”å›ï¼Œä¸åŠ ä»»ä½•"æ–‡æ¡£ç‰‡æ®µ"æ ‡ç­¾
            return "\n\n".join(r['content'] for r in results[:3])


        # å®šä¹‰æ£€ç´¢å·¥å…·
        def retrieve_context(query: str) -> str:
            """ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³å†…å®¹"""
            # ä½¿ç”¨ similarity_search_with_score è·å–åˆ†æ•°,æé«˜ç¡®å®šæ€§
            results = self.vector_store.similarity_search_with_score(query, k=3)
            
            # æŒ‰åˆ†æ•°æ’åº(åˆ†æ•°è¶Šä½è¶Šç›¸ä¼¼)
            results_sorted = sorted(results, key=lambda x: x[1])
            
            # åªä½¿ç”¨å‰2ä¸ªæœ€ç›¸å…³çš„ç»“æœ
            retrieved_docs = [doc for doc, score in results_sorted[:2]]
            
            serialized = "\n\n".join(
                f"Content: {doc.page_content}"
                for doc in retrieved_docs
            )
            return serialized
        
        retrieve_tool = StructuredTool.from_function(
            func=retrieve_context,
            name="retrieve_context",
            description="æ ¹æ®ç”¨æˆ·é—®é¢˜,ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹ã€‚",
        )
        
        tools = [retrieve_tool]
        
        #tools = [knowledge_base_search]
        
        # 3. ä½¿ç”¨ create_agentï¼ˆLangChain v1.0+ å®˜æ–¹æ¨è APIï¼‰
        self.agent = create_agent(
            model=model,
            tools=tools,
            system_prompt=self.system_prompt,
        )
        
        print(f"âœ… LangChain v1.0+ Agent åˆ›å»ºæˆåŠŸ (create_agent): {self.agent_name} and system_prompt ({self.system_prompt})")
    
    def ask(self, question: str) -> str:
        """
        å‘ Agent æé—®ï¼ˆä½¿ç”¨ LangChain v1.0+ create_agentï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            str: Agent å›ç­”
        """
        try:
            # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦ä¸ºç©º
            stats = self.vector_manager.get_statistics(self.agent_name)
            if stats and stats.get("total_vectors", 0) == 0:
                empty_kb_msg = "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚ç›®å‰æˆ‘çš„çŸ¥è¯†åº“è¿˜æ˜¯ç©ºçš„ï¼Œè¯·ç®¡ç†å‘˜å…ˆä¸Šä¼ ç›¸å…³æ–‡æ¡£ï¼Œæˆ‘æ‰èƒ½æ›´å¥½åœ°ä¸ºæ‚¨æœåŠ¡ã€‚"
                return empty_kb_msg
            
            # æ„å»ºæ¶ˆæ¯å†å²ï¼ˆLangGraph State æ ¼å¼ï¼‰
            messages = []
            # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆä¿ç•™æœ€è¿‘10è½®ï¼‰
            messages.extend(self.chat_history[-10:])
            # æ·»åŠ å½“å‰ç”¨æˆ·é—®é¢˜
            messages.append({"role": "user", "content": question})
            
            # ä½¿ç”¨ Agent æ‰§è¡Œï¼ˆLangGraph APIï¼‰
            result = self.agent.invoke({"messages": messages})
            
            # æå–æœ€åä¸€æ¡ AI æ¶ˆæ¯
            final_messages = result.get("messages", [])
            if final_messages:
                answer = final_messages[-1].content
            else:
                answer = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
            
            # æ›´æ–°å¯¹è¯å†å²ï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼‰
            import time
            timestamp = int(time.time())  # Unix æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            
            self.chat_history.append(HumanMessage(
                content=question,
                additional_kwargs={"timestamp": timestamp}
            ))
            self.chat_history.append(AIMessage(
                content=answer,
                additional_kwargs={"timestamp": timestamp}
            ))
            
            return answer
            
        except Exception as e:
            print(f"âŒ Agent å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
    
    async def ask_stream(self, question: str):
        """
        å‘ Agent æé—®ï¼ˆæµå¼å“åº”ï¼ŒLangChain v1.0+ create_agentï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Yields:
            str: é€å—è¿”å›çš„å›ç­”å†…å®¹
        """
        try:
            # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦ä¸ºç©º
            stats = self.vector_manager.get_statistics(self.agent_name)
            if stats and stats.get("total_vectors", 0) == 0:
                empty_kb_msg = "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚ç›®å‰æˆ‘çš„çŸ¥è¯†åº“è¿˜æ˜¯ç©ºçš„ï¼Œè¯·ç®¡ç†å‘˜å…ˆä¸Šä¼ ç›¸å…³æ–‡æ¡£ï¼Œæˆ‘æ‰èƒ½æ›´å¥½åœ°ä¸ºæ‚¨æœåŠ¡ã€‚"
                yield empty_kb_msg
                return
            
            # æ„å»ºæ¶ˆæ¯å†å²
            messages = []
            messages.extend(self.chat_history[-10:])
            messages.append({"role": "user", "content": question})
            
            # Agent æµå¼å“åº”ï¼ˆLangGraph stream APIï¼‰
            full_response = ""
            last_content_length = 0
            
            async for chunk in self.agent.astream(
                {"messages": messages},
                stream_mode="values"  # æµå¼è¾“å‡ºçŠ¶æ€å€¼
            ):
                # è·å–æœ€æ–°æ¶ˆæ¯
                latest_messages = chunk.get("messages", [])
                if latest_messages:
                    latest_message = latest_messages[-1]
                    
                    # å¦‚æœæ˜¯ AI æ¶ˆæ¯ï¼Œæµå¼è¾“å‡ºå†…å®¹
                    if hasattr(latest_message, "content") and latest_message.content:
                        content = latest_message.content
                        # åªè¾“å‡ºæ–°å¢çš„å†…å®¹ï¼ˆå¢é‡è¾“å‡ºï¼‰
                        if len(content) > last_content_length:
                            new_content = content[last_content_length:]
                            last_content_length = len(content)
                            full_response = content
                            yield new_content
                    
                    # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼Œæ‰“å°æ—¥å¿—
                    elif hasattr(latest_message, "tool_calls") and latest_message.tool_calls:
                        for tc in latest_message.tool_calls:
                            print(f"ğŸ”§ Agent æ­£åœ¨ä½¿ç”¨å·¥å…·: {tc.get('name', 'unknown')}")
            
            # æ›´æ–°å¯¹è¯å†å²ï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼‰
            if full_response:
                import time
                timestamp = int(time.time())  # Unix æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
                
                self.chat_history.append(HumanMessage(
                    content=question,
                    additional_kwargs={"timestamp": timestamp}
                ))
                self.chat_history.append(AIMessage(
                    content=full_response,
                    additional_kwargs={"timestamp": timestamp}
                ))
            
        except Exception as e:
            print(f"âŒ Agent æµå¼å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            yield "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
    
    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.chat_history = []
        print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…é™¤")
    
    def update_system_prompt(self, new_prompt: str):
        """æ›´æ–°ç³»ç»Ÿæç¤ºè¯"""
        if not new_prompt or not new_prompt.strip():
            raise ValueError("system_prompt ä¸èƒ½ä¸ºç©º")
        self.system_prompt = new_prompt.strip()
        self._create_agent()
        print(f"âœ… ç³»ç»Ÿæç¤ºè¯å·²æ›´æ–°: {self.agent_name}")
    
    def get_system_prompt(self) -> str:
        """è·å–å½“å‰ç³»ç»Ÿæç¤ºè¯"""
        return self.system_prompt

